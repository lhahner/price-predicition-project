import pandas as pd
import numpy as np

# ---------------------------------------------------------------
# TODO: list of todos:
# - normalize (how and what to normalize?)
# - export cleaned dataframes somehow (either to csv or return them)
# - calendar dataframe: maybe aggregate future prices for each listingID to reduce size


reviews_df = pd.read_csv('data/reviews.csv')
listings_df = pd.read_csv('data/listings.csv')
calendar_df = pd.read_csv('data/calendar.csv')

# debugging shape printing
# print ("Listings df shape:", listings_df.shape)
# print ("Reviews df shape:", reviews_df.shape)
# print ("Calendar df shape:", calendar_df.shape)


# ---------------------------------------------------------------
# CLEAN THE LISTINGS DATAFRAME
# ---------------------------------------------------------------

# remove columns with too many missing values or unnecessary information
listings_df.drop(columns=[
    'neighborhood_overview', 'host_about', 'host_location',
    'host_response_time', 'host_response_rate', 'host_acceptance_rate',
    'host_is_superhost', 'host_neighbourhood', 'host_verifications',
    'host_thumbnail_url', 'license', 'calendar_updated',
    'calendar_last_scraped', 'last_review', 'first_review', 'neighbourhood_group_cleansed',
    'last_scraped', 'source'
], inplace=True)

# remove rows with missing values in important columns
listings_df.dropna(subset=['price', 'latitude', 'longitude', 'accommodates', 'bedrooms', 'beds'], inplace=True)

# turn price column into float, removing dollar sign
listings_df['price'] = listings_df['price'].str.replace('[$,]', '', regex=True).astype(float)


# ---------------------------------------------------------------
# CLEAN THE REVIEWS DATAFRAME
# ---------------------------------------------------------------

# remove columns with too many missing values or unnecessary information
# TODO: Add columns to drop if necessary. I think if we use this for sentiment analysis, we dont need a lot of the columns.
reviews_df.drop(columns=['date', 'reviewer_id', 'reviewer_name'], inplace=True)

# remove rows with missing values in important columns, in this case no comments
reviews_df.dropna(subset=['comments'], inplace=True)

    

# ---------------------------------------------------------------
# CLEAN THE CALENDAR DATAFRAME
# ---------------------------------------------------------------


# remove columns with too many missing values or unnecessary information
# TODO : Add columns to drop if necessary
calendar_df.drop(columns=['adjusted_price'], inplace=True)

# turn price column into float, removing dollar sign
calendar_df['price'] = calendar_df['price'].str.replace('[$,]', '', regex=True).astype(float)
print(calendar_df.head())

# TODO: idea- we could aggregate the future prices for each listingID to reduce the size of the dataframe since 
# the prices tend to not fluctuate too much

# ---------------------------------------------------------------
# JOINS OF DATAFRAMES
# ---------------------------------------------------------------

# TODO: Real join, this one is only a fake generated by the AI
# full_df = pd.merge(reviews_df, listings_df, on='listing_id', how='inner')


# TODO: return?, or perhaps save the cleaned dataframes to csv files
# like this: 
# listings_df.to_csv('data/cleaned_listings.csv', index=False)